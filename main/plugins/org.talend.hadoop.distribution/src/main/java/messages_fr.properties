DynamicDistributionUtils.monitor.userCancel=Annulation utilisateur.
DynamicDistributionUtils.check.sparkVersion.unsupport=Ne supporte pas la version de Spark : {0}.
DynamicModuleAdapter.monitor.buildModule=Collecte des d\u00E9pendances de {0}, URI MVN : {1}
DynamicModuleAdapter.exception.exclusion.unsupport=Ne supporte pas l'ajout d'exclusions pour {0}, seul le type BASE est support\u00E9
DynamicModuleAdapter.exception.reference.notFound=Biblioth\u00E8que existante introuvable : {0}
DynamicModuleAdapter.exception.version.notFound=Impossible de trouver la version correspondante de {0} pour {1} :{2}
DynamicModuleAdapter.exception.wrongConfig=La configuration du mod\u00E8le de {0} n'est pas correcte, v\u00E9rifiez.
DynamicModuleGroupAdapter.monitor.buildModuleGroup=G\u00E9n\u00E9ration du groupe de modules pour {0}
DynamicModuleGroupAdapter.exception.noModuleAdapterFound=Erreur lors de la collecte des d\u00E9pendances de {0} dans  {1}
DynamicDistriConfigAdapter.diffDistri=Distributions diff\u00E9rentes : {0} <> {1}
DynamicClassloaderAdapter.exception.noModuleAdapterFound=Groupe de modules d'ID {0} introuvable, si ce n'est pas une erreur, consultez {1}
DynamicClassloaderAdapter.monitor.buildClassLoader=G\u00E9n\u00E9ration du chargeur de classe pour {0}
DynamicDistribution.name.project={0} [{1}]
DynamicDistribution.name.builtin={0} [Built-in]
DynamicDistribution.name.current=Projet courant
DynamicLibraryNeededExtensionAdaper.monitor.waitAllFinish=Dans l'attente de la fin des sous-t\u00E2ches {0}...
EDatabriksCloudProvider.AWS=AWS
EDatabriksCloudProvider.Azure=Azure
EDatabriksSubmitMode.CREATE_RUN_JOB=Cr\u00E9er et ex\u00E9cuter maintenant
EDatabriksSubmitMode.RUN_SUBMIT=Soumettre les ex\u00E9cutions
ESparkMode.CLUSTER=Standalone
ESparkMode.YARN_CLIENT=Client YARN
ESparkMode.YARN_CLUSTER=Cluster YARN
ESparkMode.KUBERNETES=Kubernetes
ESparkMode.SPARK_LOCAL=Local
ESparkMode.CDE=Cloudera Data Engineering
ESparkMode.DATAPROC=Dataproc
ESparkMode.DATABRICKS=Databricks
DISTRIBUTION.NAME=Distribution
SPARK_VERSION.NAME=Version
SUPPORTED_SPARK_VERSION.NAME=Version de Spark
SPARK_MODE.NAME=Mode/environnement du Runtime
DATABRICKS_RUNTIME_VERSION.NAME=Version du runtime
IMPALA_VERSION.NAME=Version
HBASE_VERSION.NAME=Version de HBase
HIVE_VERSION.NAME=Version de Hive
DB_VERSION.NAME=Version
